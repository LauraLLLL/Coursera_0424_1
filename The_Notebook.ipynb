{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LauraLLLL/Coursera_0424_1/blob/main/The_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrjgoos7ndHq"
      },
      "source": [
        "Importing the modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWWAMaWylijD"
      },
      "source": [
        "# Welcome to the notebook ðŸ™‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FF-XdZOlrBz"
      },
      "source": [
        "### Task 1 - Importing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rg59XDzGlmNx",
        "outputId": "81f9de59-8d66-40c4-855d-18f8dae07e59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modules are imported!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Importing neural network modules\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, BatchNormalization, LeakyReLU, Dropout\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "# Importing some machine learning modules\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Import data visualization modules\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "print(\"Modules are imported!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxu6Q7kGnoFc"
      },
      "source": [
        "Importing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QulLdZ53nqBF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F61uPjLozPzn"
      },
      "source": [
        "Check the data shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ie9B694UlDok"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "782ekqkDsAZ8"
      },
      "source": [
        "Let's see how many genuine and limited fraudulent records we have"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owr545uamDd_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p30Sel1l0zHe"
      },
      "source": [
        "### Task 2 - Data Preprocessing and Exploration\n",
        "\n",
        "*   Removing all the rows with `Nan` values\n",
        "*   Removing `Time` column\n",
        "*   Feature Scaling `Amount` column\n",
        "*   Split the data into features and labels\n",
        "*   Data Exploration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyrwqwZWzclz"
      },
      "source": [
        "Removing the rows `Nan` values in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oQ7BUhtzhJf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3qtMCEcil5E"
      },
      "source": [
        "Removing Time column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tBZhNbvinPu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEChnc_GiAkd"
      },
      "source": [
        "Feature Scaling of Amount column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nykH6OHOiHZx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvxgYLZJ0Fgg"
      },
      "source": [
        "Let's split the genuine and fraud records into separate dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KosQdd1yys4N"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AweLq-TNbyyy"
      },
      "source": [
        "Split the data into features and labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuNEggqWcY3S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uWA4S5HhY02"
      },
      "source": [
        "Data Exploration\n",
        "  - Apply PCA to reduce the dimensionality of features `X` into two dimensions\n",
        "  - Use a scatter plot to visualize our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oc4JvsU9UaQH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkrSGlnZVmdc"
      },
      "source": [
        "Let's Use a scatter plot to visualize our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAJ9F9LIVjs_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgFgpoOAS-8I"
      },
      "source": [
        "### Task 3 - Building the Generator Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GS_SZ2gZKzd"
      },
      "source": [
        "Write a method to create the Generator model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56eOgnOdTA9n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ypwr3yYYaSq5"
      },
      "source": [
        "### Task 4 - Building the Discriminator Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-78WbhfmaZ8t"
      },
      "source": [
        "Write a method to create the Discriminator model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfxnnV3uagl1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYIW2eB6bWg6"
      },
      "source": [
        "### Task 5 - Combine Generator and Discriminator models to Build The GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vt2h8iDxzEp6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZCGFIKuzXxe"
      },
      "source": [
        "Let's create a method that generates synthetic data using the Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPHMbppazcvb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXNZbInhmW5i"
      },
      "source": [
        "### Task 6 - Train and evaluate our GAN\n",
        "*    Defining some variables\n",
        "*    Creating our GAN\n",
        "*    Training the GAN\n",
        "*    Monitor the GAN performance using PCA\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7Vf9ZCE545g"
      },
      "outputs": [],
      "source": [
        "def monitor_generator(generator):\n",
        "    # Initialize a PCA (Principal Component Analysis) object with 2 components\n",
        "    pca = PCA(n_components=2)\n",
        "\n",
        "    # Drop the 'Class' column from the fraud dataset to get real data\n",
        "    real_fraud_data = data_fraud.drop(\"Class\", axis=1)\n",
        "\n",
        "    # Transform the real fraud data using PCA\n",
        "    transformed_data_real = pca.fit_transform(real_fraud_data.values)\n",
        "\n",
        "    # Create a DataFrame for the transformed real data and add a 'label' column with the value 'real'\n",
        "    df_real = pd.DataFrame(transformed_data_real)\n",
        "    df_real['label'] = \"real\"\n",
        "\n",
        "    # Generate synthetic fraud data using the provided generator and specify the number of samples (492 in this case)\n",
        "    synthetic_fraud_data = generate_synthetic_data(generator, 492)\n",
        "\n",
        "    # Transform the synthetic fraud data using PCA\n",
        "    transformed_data_fake = pca.fit_transform(synthetic_fraud_data)\n",
        "\n",
        "    # Create a DataFrame for the transformed fake data and add a 'label' column with the value 'fake'\n",
        "    df_fake = pd.DataFrame(transformed_data_fake)\n",
        "    df_fake['label'] = \"fake\"\n",
        "\n",
        "    # Concatenate the real and fake data DataFrames\n",
        "    df_combined = pd.concat([df_real, df_fake])\n",
        "\n",
        "    # Create a scatterplot to visualize the data points, using the first and second PCA components as x and y, respectively,\n",
        "    # and color points based on the 'label' column, with a size of 10\n",
        "    plt.figure()\n",
        "    sns.scatterplot(data=df_combined, x=0, y=1, hue='label', s=10)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Grtte84z-NiK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCHApltUa3Yh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlGLX4Uk6l2C"
      },
      "source": [
        "### Task 7 - Generate synthetic data using the trained Generator\n",
        "\n",
        "*   Generate 1000 fradulent data points using the trained generator\n",
        "*   Compare the distribution of `real` and `synthetic` fradulent data points.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BA1OkRU5UHOw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRp9QVL2VzrF"
      },
      "source": [
        "Checking the individual feature distribution of `synthetic` and `real` fraud data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "VjR196XqKfVd",
        "outputId": "1414506b-7621-45c6-edbb-30f98af536f9"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-7712b9dc83b8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombined_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbarmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"overlay\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'Feature {col}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'combined_df' is not defined"
          ]
        }
      ],
      "source": [
        "for col in combined_df.columns:\n",
        "  plt.figure()\n",
        "  fig = px.histogram(combined_df, color = 'label', x=col,barmode=\"overlay\", title = f'Feature {col}', width = 640, height = 500)\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzZuOOGPHvZu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}